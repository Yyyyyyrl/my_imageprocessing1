{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JPEG Compression with Zonal Coding Quantization\n",
    "stough 202-\n",
    "DIP 8.9\n",
    "\n",
    "In this activity we're going to synthesize a bit of the [JPEG](https://en.wikipedia.org/wiki/JPEG) encoding standard, specifically block transform encoding and zonal coding quantization. We will look to understand how the quantization affects the image reconstruction.\n",
    "\n",
    "Read up in DIP 8.9 or [elsewhere](https://en.wikipedia.org/wiki/JPEG#JPEG_codec_example) if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "We're going to take advantage of both [`view_as_blocks`](https://scikit-image.org/docs/dev/api/skimage.util.html?highlight=view_as_blocks#skimage.util.view_as_blocks) and the [Discrete Cosine transform](https://en.wikipedia.org/wiki/Discrete_cosine_transform) for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# For importing from alternative directory sources\n",
    "import sys  \n",
    "sys.path.insert(0, '../dip_utils')\n",
    "\n",
    "from matrix_utils import (arr_info,\n",
    "                          make_linmap)\n",
    "from vis_utils import (vis_rgb_cube,\n",
    "                       vis_hists,\n",
    "                       vis_pair,\n",
    "                       vis_surface)\n",
    "\n",
    "from wavelet_utils import (make_haar_matrix,\n",
    "                           make_random_basis,\n",
    "                           make_klt_basis,\n",
    "                           make_dct_matrix,\n",
    "                           make_standard_matrix,\n",
    "                           vis_blocks)\n",
    "\n",
    "from skimage.util import view_as_blocks\n",
    "from skimage.util import montage\n",
    "from skimage.transform import resize, rescale\n",
    "from ipywidgets import VBox, HBox, FloatSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPEG Compression\n",
    "Basically\n",
    "- Take the image in $[0,255]$ form and subtract 128. This is to center around 0. Make sure you change the `dtype` when you do this, or else you won't be able to represent negatives.\n",
    "- Transform each 8x8 block using the DCT transform matrix (see `make_dct_matrix`)\n",
    "- Quantize the transform coefficients according the [Q matrix](https://en.wikipedia.org/wiki/JPEG#Quantization). This is, divide the block coefficients and store the result in integer form.\n",
    "- These quantized transform blocks represent how the compressed image would be stored or transmitted. We won't go further than just having this representation, as the point of the exercise is to understand how this quantization affects the reconstruction. \n",
    "- Reconstruction: for each transform block, remultiply according to the Q matrix and then invert the transform process, to reconstruct the as-though-compressed image block.\n",
    "\n",
    "We'll define the Q matrix for ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af90148a52b3465a9787ccd954b0f3c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "H = make_dct_matrix(8)\n",
    "vis_blocks(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[215., 215., 215., 215., 215., 215., 215., 215.],\n",
       "       [215., 215., 215., 215., 215., 215., 215., 215.],\n",
       "       [215., 215., 215., 215., 215., 215., 215., 215.],\n",
       "       [215., 215., 215., 215., 215., 215., 215., 215.],\n",
       "       [215., 215., 215., 215., 215., 215., 215., 215.],\n",
       "       [215., 215., 215., 215., 215., 215., 215., 215.],\n",
       "       [215., 215., 215., 215., 215., 215., 215., 215.],\n",
       "       [215., 215., 215., 215., 215., 215., 215., 215.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = 215 * np.ones((8,8))\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[87., 87., 87., 87., 87., 87., 87., 87.],\n",
       "       [87., 87., 87., 87., 87., 87., 87., 87.],\n",
       "       [87., 87., 87., 87., 87., 87., 87., 87.],\n",
       "       [87., 87., 87., 87., 87., 87., 87., 87.],\n",
       "       [87., 87., 87., 87., 87., 87., 87., 87.],\n",
       "       [87., 87., 87., 87., 87., 87., 87., 87.],\n",
       "       [87., 87., 87., 87., 87., 87., 87., 87.],\n",
       "       [87., 87., 87., 87., 87., 87., 87., 87.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B128 = B.astype('float')-128\n",
    "B128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.96000000e+02,  6.78279942e-14, -5.58952915e-14,\n",
       "         3.79962375e-14,  3.45420341e-14,  1.93749409e-13,\n",
       "        -1.34949447e-13, -9.02018118e-14],\n",
       "       [ 3.14853305e-14,  5.52202634e-30, -5.71924156e-30,\n",
       "         3.64848169e-30,  1.38050658e-30,  2.49477261e-29,\n",
       "        -8.75142567e-30, -5.54667824e-30],\n",
       "       [-6.93491172e-14, -5.71924156e-30,  4.28943117e-30,\n",
       "        -2.93357649e-30, -4.38803879e-30, -2.38383905e-29,\n",
       "         1.75090143e-29,  1.17527949e-29],\n",
       "       [ 3.52598442e-14,  5.22620350e-30, -3.72243740e-30,\n",
       "         1.46678825e-30,  2.19401939e-30,  1.34969171e-29,\n",
       "        -9.93779851e-30, -4.69310609e-30],\n",
       "       [ 2.43132171e-14,  2.16936749e-30, -2.81031697e-30,\n",
       "         1.79958894e-30,  1.13398755e-30,  8.50490663e-30,\n",
       "        -9.90390215e-30, -2.64391663e-30],\n",
       "       [ 1.89021637e-13,  1.94256998e-29, -1.59497814e-29,\n",
       "         1.07359039e-29,  9.29376754e-30,  5.74759125e-29,\n",
       "        -3.99638167e-29, -2.57458315e-29],\n",
       "       [-1.38739241e-13, -1.32873759e-29,  1.02120509e-29,\n",
       "        -6.78235489e-30, -6.45263569e-30, -3.63153350e-29,\n",
       "         2.42751914e-29,  1.66870274e-29],\n",
       "       [-7.84268758e-14, -8.50490663e-30,  7.61127514e-30,\n",
       "        -4.49589086e-30, -4.32024605e-30, -2.56472239e-29,\n",
       "         1.79196226e-29,  1.30893903e-29]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = np.matmul(H, np.matmul(B128,H.transpose()))\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44.,  0., -0.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  0., -0.,  0.,  0.,  0., -0., -0.],\n",
       "       [-0., -0.,  0., -0., -0., -0.,  0.,  0.],\n",
       "       [ 0.,  0., -0.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  0., -0.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  0., -0.,  0.,  0.,  0., -0., -0.],\n",
       "       [-0., -0.,  0., -0., -0., -0.,  0.,  0.],\n",
       "       [-0., -0.,  0., -0., -0., -0.,  0.,  0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tq = np.round(T/Q)\n",
    "Tq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Interactive Quantization Demo\n",
    "Put together an interactive demo that shows the original image, its current reconstruction, and a view of the currently quantized transform coefficients. This demo should then interact with a `FloatSlider` that affects the multiple applied to the Q quantization matrix. This demo would show how you could increase the compression (increasing the multiple) and what that increased compression would do to the image reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.array([[16, 11, 10, 16, 24, 40, 51, 61],\n",
    "              [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "              [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "              [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "              [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "              [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "              [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "              [72, 92, 95, 98, 112, 100, 103, 99]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "H2 = make_dct_matrix(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b91cafb7ee8405ba8f11b828622b4a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "I = plt.imread(\"../dip_pics/mountainSpring.jpg\")\n",
    "I = ((I - I.min()) / (I.max() - I.min()) * 255).astype('uint8') # Normalization\n",
    "vis_hists(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1200, 1600, 3), dtype('uint8'), 0, 255)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_info(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_shape = (8,8,3)\n",
    "Blocks = view_as_blocks(I, block_shape) # list of original images\n",
    "blocklist = np.reshape(Blocks, [Blocks.shape[0]*Blocks.shape[1]] + list(block_shape))\n",
    "#arr_info(block_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_quantization(mult, Blocks, D, Q):\n",
    "    global blocklist\n",
    "    \n",
    "    ReconsQ = blocklist.copy().astype('float')\n",
    "    TransQ = blocklist.copy().astype('float')\n",
    "    \n",
    "    for index, block in enumerate(blocklist):\n",
    "        ReconsQ_block = block.copy().astype('float')\n",
    "        temp = block.astype('float')-128\n",
    "        for channel in range(3):\n",
    "            TransQ[index][...,channel] = np.round(np.matmul(D, np.matmul(temp[...,channel],D.transpose()))/(mult*Q)) # Generate the coefficient matrix for a channel, then quantize it by a multiple m\n",
    "            ReconsQ_block[...,channel] = np.matmul(D.transpose(), np.matmul(TransQ[index][...,channel]*mult*Q, D)) + 128 # Reconstruct by reverse process\n",
    "        \n",
    "        ReconsQ[index] = ReconsQ_block # Update the reconstructed Image\n",
    "        \n",
    "\n",
    "    return np.clip(montage(ReconsQ, grid_shape = Blocks.shape[:2], multichannel=True, padding_width = 0, fill=[1,1,1]),0,255)/255, np.clip(montage(TransQ, grid_shape = Blocks.shape[:2], multichannel=True, padding_width = 0, fill=[1,1,1]),0,255)/255\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34b2c42410944c4b0ede744ecfe1a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FloatSlider(value=1.0, description='Multiple of Q', max=5.0, min=0.2, step=0.01), Canvas(toolbaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ioff()\n",
    "plt.clf()\n",
    "\n",
    "coeff_slider = FloatSlider(\n",
    "    orientation = 'horizontal',\n",
    "    value = 1.00,\n",
    "    min = 0.20,\n",
    "    max = 5.00,\n",
    "    step = 0.01,\n",
    "    description = 'Multiple of Q'\n",
    ")\n",
    "\n",
    "fig_args = {'num':' ', 'frameon':True, 'sharex':True, 'sharey':True}\n",
    "fig, ax = plt.subplots(1,3, figsize=(8,3), **fig_args) \n",
    "\n",
    "Original = ax[0].imshow(I[440:640,720:880,:])\n",
    "ax[0].set_title(\"Original Image\")\n",
    "Reconstruct = ax[1].imshow(I[440:640,720:880,:])\n",
    "ReconTitle = ax[1].set_title(\"Reconstructed using quantized DCT\")\n",
    "Coeff = ax[2].imshow(I[440:640,720:880,:])\n",
    "text = ax[2].set_title(\"Quantized Coefficients\")\n",
    "\n",
    "\n",
    "\n",
    "def update(change):\n",
    "    global Original, Reconstruct, Coeff, text\n",
    "    ReconQ, TransQ = make_quantization(change.new, Blocks,H2,Q)\n",
    "    Reconstruct.set_array(ReconQ[440:640,720:880,:])\n",
    "    ReconTitle.set_text(f'Quantized Reconstruction \\n with multiple: { format(change.new)}')\n",
    "    Coeff.set_array(TransQ[440:640,720:880,:])\n",
    "    text.set_text(f'Coeff with multiple \\n of { format(change.new)}')\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "\n",
    "coeff_slider.observe(update, names = 'value')\n",
    "\n",
    "plt.tight_layout()\n",
    "VBox([coeff_slider, fig.canvas])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
